{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "这个文件用于研究多通道频域WPE算法\n",
    "暂定其输出为2通道"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "from nara_wpe.utils import stft, istft\n",
    "import numpy as np\n",
    "import IPython\n",
    "import functools\n",
    "import operator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "## 此处用于容纳WPE算法本体\n",
    "\n",
    "def segment_axis(\n",
    "        x,\n",
    "        length,\n",
    "        shift,\n",
    "        axis=-1,\n",
    "        end='cut',  # in ['pad', 'cut', None]\n",
    "        pad_mode='constant',\n",
    "        pad_value=0,\n",
    "):\n",
    "\n",
    "    \"\"\"Generate a new array that chops the given array along the given axis\n",
    "     into overlapping frames.\n",
    "\n",
    "    Note: if end='pad' the return is maybe a copy\n",
    "\n",
    "    Args:\n",
    "        x: The array to segment\n",
    "        length: The length of each frame\n",
    "        shift: The number of array elements by which to step forward\n",
    "               Negative values are also allowed.\n",
    "        axis: The axis to operate on; if None, act on the flattened array\n",
    "        end: What to do with the last frame, if the array is not evenly\n",
    "                divisible into pieces. Options are:\n",
    "                * 'cut'   Simply discard the extra values\n",
    "                * None    No end treatment. Only works when fits perfectly.\n",
    "                * 'pad'   Pad with a constant value\n",
    "                * 'conv_pad' Special padding for convolution, assumes\n",
    "                             shift == 1, see example below\n",
    "        pad_mode: see numpy.pad\n",
    "        pad_value: The value to use for end='pad'\n",
    "\n",
    "    Examples:\n",
    "        >>> # import cupy as np\n",
    "        >>> segment_axis(np.arange(10), 4, 2)  # simple example\n",
    "        array([[0, 1, 2, 3],\n",
    "               [2, 3, 4, 5],\n",
    "               [4, 5, 6, 7],\n",
    "               [6, 7, 8, 9]])\n",
    "        >>> segment_axis(np.arange(10), 4, -2)  # negative shift\n",
    "        array([[6, 7, 8, 9],\n",
    "               [4, 5, 6, 7],\n",
    "               [2, 3, 4, 5],\n",
    "               [0, 1, 2, 3]])\n",
    "        >>> segment_axis(np.arange(5).reshape(5), 4, 1, axis=0)\n",
    "        array([[0, 1, 2, 3],\n",
    "               [1, 2, 3, 4]])\n",
    "        >>> segment_axis(np.arange(5).reshape(5), 4, 2, axis=0, end='cut')\n",
    "        array([[0, 1, 2, 3]])\n",
    "        >>> segment_axis(np.arange(5).reshape(5), 4, 2, axis=0, end='pad')\n",
    "        array([[0, 1, 2, 3],\n",
    "               [2, 3, 4, 0]])\n",
    "        >>> segment_axis(np.arange(5).reshape(5), 4, 1, axis=0, end='conv_pad')\n",
    "        array([[0, 0, 0, 0],\n",
    "               [0, 0, 0, 1],\n",
    "               [0, 0, 1, 2],\n",
    "               [0, 1, 2, 3],\n",
    "               [1, 2, 3, 4],\n",
    "               [2, 3, 4, 0],\n",
    "               [3, 4, 0, 0],\n",
    "               [4, 0, 0, 0]])\n",
    "        >>> segment_axis(np.arange(6).reshape(6), 4, 2, axis=0, end='pad')\n",
    "        array([[0, 1, 2, 3],\n",
    "               [2, 3, 4, 5]])\n",
    "        >>> segment_axis(np.arange(10).reshape(2, 5), 4, 1, axis=-1)\n",
    "        array([[[0, 1, 2, 3],\n",
    "                [1, 2, 3, 4]],\n",
    "        <BLANKLINE>\n",
    "               [[5, 6, 7, 8],\n",
    "                [6, 7, 8, 9]]])\n",
    "        >>> segment_axis(np.arange(10).reshape(5, 2).T, 4, 1, axis=1)\n",
    "        array([[[0, 2, 4, 6],\n",
    "                [2, 4, 6, 8]],\n",
    "        <BLANKLINE>\n",
    "               [[1, 3, 5, 7],\n",
    "                [3, 5, 7, 9]]])\n",
    "        >>> segment_axis(np.asfortranarray(np.arange(10).reshape(2, 5)),\n",
    "        ...                 4, 1, axis=1)\n",
    "        array([[[0, 1, 2, 3],\n",
    "                [1, 2, 3, 4]],\n",
    "        <BLANKLINE>\n",
    "               [[5, 6, 7, 8],\n",
    "                [6, 7, 8, 9]]])\n",
    "        >>> segment_axis(np.arange(8).reshape(2, 2, 2).transpose(1, 2, 0),\n",
    "        ...                 2, 1, axis=0, end='cut')\n",
    "        array([[[[0, 4],\n",
    "                 [1, 5]],\n",
    "        <BLANKLINE>\n",
    "                [[2, 6],\n",
    "                 [3, 7]]]])\n",
    "        >>> a = np.arange(7).reshape(7)\n",
    "        >>> b = segment_axis(a, 4, -2, axis=0, end='cut')\n",
    "        >>> a += 1  # a and b point to the same memory\n",
    "        >>> b\n",
    "        array([[3, 4, 5, 6],\n",
    "               [1, 2, 3, 4]])\n",
    "\n",
    "        >>> segment_axis(np.arange(7), 8, 1, axis=0, end='pad').shape\n",
    "        (1, 8)\n",
    "        >>> segment_axis(np.arange(8), 8, 1, axis=0, end='pad').shape\n",
    "        (1, 8)\n",
    "        >>> segment_axis(np.arange(9), 8, 1, axis=0, end='pad').shape\n",
    "        (2, 8)\n",
    "        >>> segment_axis(np.arange(7), 8, 2, axis=0, end='cut').shape\n",
    "        (0, 8)\n",
    "        >>> segment_axis(np.arange(8), 8, 2, axis=0, end='cut').shape\n",
    "        (1, 8)\n",
    "        >>> segment_axis(np.arange(9), 8, 2, axis=0, end='cut').shape\n",
    "        (1, 8)\n",
    "\n",
    "        >>> x = np.arange(1, 10)\n",
    "        >>> filter_ = np.array([1, 2, 3])\n",
    "        >>> np.convolve(x, filter_)\n",
    "        array([ 1,  4, 10, 16, 22, 28, 34, 40, 46, 42, 27])\n",
    "        >>> x_ = segment_axis(x, len(filter_), 1, end='conv_pad')\n",
    "        >>> x_\n",
    "        array([[0, 0, 1],\n",
    "               [0, 1, 2],\n",
    "               [1, 2, 3],\n",
    "               [2, 3, 4],\n",
    "               [3, 4, 5],\n",
    "               [4, 5, 6],\n",
    "               [5, 6, 7],\n",
    "               [6, 7, 8],\n",
    "               [7, 8, 9],\n",
    "               [8, 9, 0],\n",
    "               [9, 0, 0]])\n",
    "        >>> x_ @ filter_[::-1]  # Equal to convolution\n",
    "        array([ 1,  4, 10, 16, 22, 28, 34, 40, 46, 42, 27])\n",
    "\n",
    "        >>> segment_axis(np.arange(19), 16, 4, axis=-1, end='pad')\n",
    "        array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
    "               [ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,  0]])\n",
    "\n",
    "        >>> import torch\n",
    "        >>> segment_axis(torch.tensor(np.arange(10)), 4, 2)  # simple example\n",
    "        tensor([[0, 1, 2, 3],\n",
    "                [2, 3, 4, 5],\n",
    "                [4, 5, 6, 7],\n",
    "                [6, 7, 8, 9]])\n",
    "        >>> segment_axis(torch.tensor(np.arange(10) + 1j), 4, 2)  # simple example\n",
    "        tensor([[0.+1.j, 1.+1.j, 2.+1.j, 3.+1.j],\n",
    "                [2.+1.j, 3.+1.j, 4.+1.j, 5.+1.j],\n",
    "                [4.+1.j, 5.+1.j, 6.+1.j, 7.+1.j],\n",
    "                [6.+1.j, 7.+1.j, 8.+1.j, 9.+1.j]], dtype=torch.complex128)\n",
    "    \"\"\"\n",
    "    backend = {\n",
    "        'numpy': 'numpy',\n",
    "        'cupy.core.core': 'cupy',\n",
    "        'torch': 'torch',\n",
    "    }[x.__class__.__module__]\n",
    "\n",
    "    if backend == 'numpy':\n",
    "        xp = np\n",
    "    elif backend == 'cupy':\n",
    "        import cupy\n",
    "        xp = cupy\n",
    "    elif backend == 'torch':\n",
    "        import torch\n",
    "        xp = torch\n",
    "    else:\n",
    "        raise Exception('Can not happen')\n",
    "\n",
    "    try:\n",
    "        ndim = x.ndim\n",
    "    except AttributeError:\n",
    "        # For Pytorch 1.2 and below\n",
    "        ndim = x.dim()\n",
    "\n",
    "    axis = axis % ndim\n",
    "\n",
    "    # Implement negative shift with a positive shift and a flip\n",
    "    # stride_tricks does not work correct with negative stride\n",
    "    if shift > 0:\n",
    "        do_flip = False\n",
    "    elif shift < 0:\n",
    "        do_flip = True\n",
    "        shift = abs(shift)\n",
    "    else:\n",
    "        raise ValueError(shift)\n",
    "\n",
    "    if pad_mode == 'constant':\n",
    "        pad_kwargs = {'constant_values': pad_value}\n",
    "    else:\n",
    "        pad_kwargs = {}\n",
    "\n",
    "    # Pad\n",
    "    if end == 'pad':\n",
    "        if x.shape[axis] < length:\n",
    "            npad = np.zeros([ndim, 2], dtype=int)\n",
    "            npad[axis, 1] = length - x.shape[axis]\n",
    "            x = xp.pad(x, pad_width=npad, mode=pad_mode, **pad_kwargs)\n",
    "        elif shift != 1 and (x.shape[axis] + shift - length) % shift != 0:\n",
    "            npad = np.zeros([ndim, 2], dtype=int)\n",
    "            npad[axis, 1] = shift - ((x.shape[axis] + shift - length) % shift)\n",
    "            x = xp.pad(x, pad_width=npad, mode=pad_mode, **pad_kwargs)\n",
    "\n",
    "    elif end == 'conv_pad':\n",
    "        assert shift == 1, shift\n",
    "        npad = np.zeros([ndim, 2], dtype=int)\n",
    "        npad[axis, :] = length - shift\n",
    "        x = xp.pad(x, pad_width=npad, mode=pad_mode, **pad_kwargs)\n",
    "    elif end is None:\n",
    "        assert (x.shape[axis] + shift - length) % shift == 0, \\\n",
    "            '{} = x.shape[axis]({}) + shift({}) - length({})) % shift({})' \\\n",
    "            ''.format((x.shape[axis] + shift - length) % shift,\n",
    "                      x.shape[axis], shift, length, shift)\n",
    "    elif end == 'cut':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(end)\n",
    "\n",
    "    # Calculate desired shape and strides\n",
    "    shape = list(x.shape)\n",
    "    # assert shape[axis] >= length, shape\n",
    "    del shape[axis]\n",
    "    shape.insert(axis, (x.shape[axis] + shift - length) // shift)\n",
    "    shape.insert(axis + 1, length)\n",
    "\n",
    "    def get_strides(array):\n",
    "        try:\n",
    "            return list(array.strides)\n",
    "        except AttributeError:\n",
    "            # fallback for torch\n",
    "            return list(array.stride())\n",
    "\n",
    "    strides = get_strides(x)\n",
    "    strides.insert(axis, shift * strides[axis])\n",
    "\n",
    "    # Alternative to np.ndarray.__new__\n",
    "    # I am not sure if np.lib.stride_tricks.as_strided is better.\n",
    "    # return np.lib.stride_tricks.as_strided(\n",
    "    #     x, shape=shape, strides=strides)\n",
    "    try:\n",
    "        if backend == 'numpy':\n",
    "            x = np.lib.stride_tricks.as_strided(x, strides=strides, shape=shape)\n",
    "        elif backend == 'cupy':\n",
    "            x = x.view()\n",
    "            x._set_shape_and_strides(strides=strides, shape=shape)\n",
    "        elif backend == 'torch':\n",
    "            import torch\n",
    "            x = torch.as_strided(x, size=shape, stride=strides)\n",
    "        else:\n",
    "            raise Exception('Can not happen')\n",
    "\n",
    "        # return np.ndarray.__new__(np.ndarray, strides=strides,\n",
    "        #                           shape=shape, buffer=x, dtype=x.dtype)\n",
    "    except Exception:\n",
    "        print('strides:', get_strides(x), ' -> ', strides)\n",
    "        print('shape:', x.shape, ' -> ', shape)\n",
    "        try:\n",
    "            print('flags:', x.flags)\n",
    "        except AttributeError:\n",
    "            pass  # for pytorch\n",
    "        print('Parameters:')\n",
    "        print('shift:', shift, 'Note: negative shift is implemented with a '\n",
    "                               'following flip')\n",
    "        print('length:', length, '<- Has to be positive.')\n",
    "        raise\n",
    "    if do_flip:\n",
    "        return xp.flip(x, axis=axis)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_y_tilde(Y, taps, delay):\n",
    "    \"\"\"\n",
    "\n",
    "    Note: The returned y_tilde consumes a similar amount of memory as Y, because\n",
    "        of tricks with strides. Usually the memory consumprion is K times\n",
    "        smaller than the memory consumprion of a contignous array,\n",
    "\n",
    "    >>> T, D = 20, 2\n",
    "    >>> Y = np.arange(start=1, stop=T * D + 1).reshape([T, D]).T\n",
    "    >>> print(Y)\n",
    "    [[ 1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39]\n",
    "     [ 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40]]\n",
    "    >>> taps, delay = 4, 2\n",
    "    >>> Y_tilde = build_y_tilde(Y, taps, delay)\n",
    "    >>> print(Y_tilde.shape, (taps*D, T))\n",
    "    (8, 20) (8, 20)\n",
    "    >>> print(Y_tilde)\n",
    "    [[ 0  0  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35]\n",
    "     [ 0  0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36]\n",
    "     [ 0  0  0  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33]\n",
    "     [ 0  0  0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34]\n",
    "     [ 0  0  0  0  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31]\n",
    "     [ 0  0  0  0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32]\n",
    "     [ 0  0  0  0  0  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29]\n",
    "     [ 0  0  0  0  0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30]]\n",
    "    >>> Y_tilde = build_y_tilde(Y, taps, 0)\n",
    "    >>> print(Y_tilde.shape, (taps*D, T), Y_tilde.strides)\n",
    "    (8, 20) (8, 20) (-8, 16)\n",
    "    >>> print('Pseudo size:', Y_tilde.nbytes)\n",
    "    Pseudo size: 1280\n",
    "    >>> print('Reak size:', Y_tilde.base.base.base.base.nbytes)\n",
    "    Reak size: 368\n",
    "    >>> print(Y_tilde)\n",
    "    [[ 1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39]\n",
    "     [ 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40]\n",
    "     [ 0  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37]\n",
    "     [ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38]\n",
    "     [ 0  0  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35]\n",
    "     [ 0  0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36]\n",
    "     [ 0  0  0  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33]\n",
    "     [ 0  0  0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34]]\n",
    "\n",
    "    The first columns are zero because of the delay.\n",
    "\n",
    "    \"\"\"\n",
    "    S = Y.shape[:-2]\n",
    "    D = Y.shape[-2]\n",
    "    T = Y.shape[-1]\n",
    "\n",
    "    def pad(x, axis=-1, pad_width=taps + delay - 1):#将信号向后移pad_width帧\n",
    "        npad = np.zeros([x.ndim, 2], dtype=int)\n",
    "        npad[axis, 0] = pad_width\n",
    "        x = np.pad(x,\n",
    "                   pad_width=npad,\n",
    "                   mode='constant',\n",
    "                   constant_values=0)\n",
    "        return x\n",
    "\n",
    "\n",
    "    # ToDo: write the shape\n",
    "    Y_ = pad(Y)\n",
    "    Y_ = np.moveaxis(Y_, -1, -2)#23两列转置\n",
    "    Y_ = np.flip(Y_, axis=-1)#交换了转置后的每一组位置\n",
    "    Y_ = np.ascontiguousarray(Y_)#没啥卵用\n",
    "    Y_ = np.flip(Y_, axis=-1)#又换了回去\n",
    "    Y_ = segment_axis(Y_, taps, 1, axis=-2)\n",
    "    Y_ = np.flip(Y_, axis=-2)\n",
    "    if delay > 0:\n",
    "        Y_ = Y_[..., :-delay, :, :]\n",
    "    Y_ = np.reshape(Y_, list(S) + [T, taps * D])\n",
    "    Y_ = np.moveaxis(Y_, -2, -1)\n",
    "\n",
    "    return Y_\n",
    "\n",
    "\n",
    "def abs_square(x):\n",
    "    \"\"\"\n",
    "\n",
    "    Params:\n",
    "        x: np.ndarray\n",
    "\n",
    "    https://github.com/numpy/numpy/issues/9679\n",
    "\n",
    "    Bug in numpy 1.13.1\n",
    "    >> np.ones(32768).imag ** 2\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    ValueError: output array is read-only\n",
    "    >> np.ones(32767).imag ** 2\n",
    "    array([ 0.,  0.,  0., ...,  0.,  0.,  0.])\n",
    "\n",
    "    >>> abs_square(np.ones(32768)).shape\n",
    "    (32768,)\n",
    "    >>> abs_square(np.ones(32768, dtype=np.complex64)).shape\n",
    "    (32768,)\n",
    "    \"\"\"\n",
    "\n",
    "    if np.iscomplexobj(x):\n",
    "        return x.real ** 2 + x.imag ** 2\n",
    "    else:\n",
    "        return x ** 2\n",
    "\n",
    "def get_power_inverse(signal):\n",
    "\n",
    "    power = np.mean(abs_square(signal), axis=-2)\n",
    "\n",
    "    eps = 1e-10 * np.max(power)\n",
    "    if eps == 0:\n",
    "        # Special case when signal is zero.\n",
    "        # Does not happen on real data.\n",
    "        # This only happens in artificial cases, e.g. redacted signal parts,\n",
    "        # where the signal is set to be zero from a human.\n",
    "        #\n",
    "        # The scale of the power does not matter, so take 1.\n",
    "        inverse_power = np.ones_like(power)\n",
    "    else:\n",
    "        inverse_power = 1 / np.maximum(power, eps)\n",
    "    return inverse_power\n",
    "\n",
    "def window_mean(x, lr_context, axis=-1):\n",
    "    \"\"\"\n",
    "    Take the mean of x at each index with a left and right context.\n",
    "    Pseudo code for lr_context == (1, 1):\n",
    "        y = np.zeros(...)\n",
    "        for i in range(...):\n",
    "            if not edge_case(i):\n",
    "                y[i] = (x[i - 1] + x[i] + x[i + 1]) / 3\n",
    "            elif i == 0:\n",
    "                y[i] = (x[i] + x[i + 1]) / 2\n",
    "            else:\n",
    "                y[i] = (x[i - 1] + x[i]) / 2\n",
    "        return y\n",
    "\n",
    "    >>> window_mean([1, 1, 1, 1, 1], 1)\n",
    "    array([1., 1., 1., 1., 1.])\n",
    "    >>> window_mean([1, 2, 3, 4, 5], 1)\n",
    "    array([1.5, 2. , 3. , 4. , 4.5])\n",
    "    >>> x = [1, 1, 13, 1, 1]\n",
    "    >>> np.testing.assert_equal(window_mean(x, (0, 1)), [1, 7, 7, 1, 1])\n",
    "    >>> np.testing.assert_equal(window_mean(x, (1, 0)), [1, 1, 7, 7, 1])\n",
    "    >>> np.testing.assert_equal(window_mean(x, (0, 2)), [5, 5, 5, 1, 1])\n",
    "    >>> np.testing.assert_equal(window_mean(x, (2, 0)), [1, 1, 5, 5, 5])\n",
    "    >>> np.testing.assert_equal(window_mean(x, (1, 2)), [5, 4, 4, 5, 1])\n",
    "    >>> np.testing.assert_equal(window_mean(x, (2, 1)), [1, 5, 4, 4, 5])\n",
    "    >>> np.testing.assert_equal(window_mean(x, (9, 9)), [3.4] * 5)\n",
    "\n",
    "    >>> x = np.random.normal(size=(20, 50))\n",
    "    >>> lr_context = np.random.randint(0, 5, size=2)\n",
    "    >>> a = window_mean(x, lr_context, axis=1)\n",
    "    >>> b = window_mean(x, lr_context, axis=-1)\n",
    "    >>> c = window_mean(x.T, lr_context, axis=0).T\n",
    "    >>> d = [window_mean_slow(s, lr_context) for s in x]\n",
    "    >>> np.testing.assert_equal(a, b)\n",
    "    >>> np.testing.assert_equal(a, c)\n",
    "    >>> np.testing.assert_almost_equal(a, d)\n",
    "\n",
    "    >>> import bottleneck as bn\n",
    "    >>> a = window_mean(x, [lr_context[0], 0], axis=-1)\n",
    "    >>> b = bn.move_mean(x, lr_context[0] + 1, min_count=1)\n",
    "    >>> np.testing.assert_almost_equal(a, b)\n",
    "\n",
    "    >>> a = window_mean(x, [lr_context[0], 0], axis=0)\n",
    "    >>> b = bn.move_mean(x, lr_context[0] + 1, min_count=1, axis=0)\n",
    "    >>> np.testing.assert_almost_equal(a, b)\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(lr_context, int):\n",
    "        lr_context = [lr_context + 1, lr_context]\n",
    "    else:\n",
    "        assert len(lr_context) == 2, lr_context\n",
    "        tmp_l_context, tmp_r_context = lr_context\n",
    "        lr_context = tmp_l_context + 1, tmp_r_context\n",
    "\n",
    "    x = np.asarray(x)\n",
    "\n",
    "    window_length = sum(lr_context)\n",
    "    if window_length == 0:\n",
    "        return x\n",
    "\n",
    "    pad_width = np.zeros((x.ndim, 2), dtype=np.int64)\n",
    "    pad_width[axis] = lr_context\n",
    "\n",
    "    first_slice = [slice(None)] * x.ndim\n",
    "    first_slice[axis] = slice(sum(lr_context), None)\n",
    "    second_slice = [slice(None)] * x.ndim\n",
    "    second_slice[axis] = slice(None, -sum(lr_context))\n",
    "\n",
    "    def foo(x):\n",
    "        cumsum = np.cumsum(np.pad(x, pad_width, mode='constant'), axis=axis)\n",
    "        return cumsum[first_slice] - cumsum[second_slice]\n",
    "\n",
    "    ones_shape = [1] * x.ndim\n",
    "    ones_shape[axis] = x.shape[axis]\n",
    "\n",
    "    return foo(x) / foo(np.ones(ones_shape, np.int64))\n",
    "\n",
    "def get_working_shape(shape):\n",
    "    \"Flattens all but the last two dimension.\"\n",
    "    product = functools.reduce(operator.mul, [1] + list(shape[:-2]))\n",
    "    return [product] + list(shape[-2:])\n",
    "\n",
    "def _stable_solve(A, B):\n",
    "    \"\"\"\n",
    "    Use np.linalg.solve with fallback to np.linalg.lstsq.\n",
    "    Equal to np.linalg.lstsq but faster.\n",
    "\n",
    "    Note: limited currently by A.shape == B.shape\n",
    "\n",
    "    This function try's np.linalg.solve with independent dimensions,\n",
    "    when this is not working the function fall back to np.linalg.solve\n",
    "    for each matrix. If one matrix does not work it fall back to\n",
    "    np.linalg.lstsq.\n",
    "\n",
    "    The reason for not using np.linalg.lstsq directly is the execution time.\n",
    "    Examples:\n",
    "    A and B have the shape (500, 6, 6), than a loop over lstsq takes\n",
    "    108 ms and this function 28 ms for the case that one matrix is singular\n",
    "    else 1 ms.\n",
    "\n",
    "    >>> def normal(shape):\n",
    "    ...     return np.random.normal(size=shape) + 1j * np.random.normal(size=shape)\n",
    "\n",
    "    >>> A = normal((6, 6))\n",
    "    >>> B = normal((6, 6))\n",
    "    >>> C1 = np.linalg.solve(A, B)\n",
    "    >>> C2, *_ = np.linalg.lstsq(A, B)\n",
    "    >>> C3 = _stable_solve(A, B)\n",
    "    >>> C4 = _lstsq(A, B)\n",
    "    >>> np.testing.assert_allclose(C1, C2)\n",
    "    >>> np.testing.assert_allclose(C1, C3)\n",
    "    >>> np.testing.assert_allclose(C1, C4)\n",
    "\n",
    "    >>> A = np.zeros((6, 6), dtype=np.complex128)\n",
    "    >>> B = np.zeros((6, 6), dtype=np.complex128)\n",
    "    >>> C1 = np.linalg.solve(A, B)\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    numpy.linalg.LinAlgError: Singular matrix\n",
    "    >>> C2, *_ = np.linalg.lstsq(A, B)\n",
    "    >>> C3 = _stable_solve(A, B)\n",
    "    >>> C4 = _lstsq(A, B)\n",
    "    >>> np.testing.assert_allclose(C2, C3)\n",
    "    >>> np.testing.assert_allclose(C2, C4)\n",
    "\n",
    "    >>> A = normal((3, 6, 6))\n",
    "    >>> B = normal((3, 6, 6))\n",
    "    >>> C1 = np.linalg.solve(A, B)\n",
    "    >>> C2, *_ = np.linalg.lstsq(A, B)\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    numpy.linalg.LinAlgError: 3-dimensional array given. Array must be two-dimensional\n",
    "    >>> C3 = _stable_solve(A, B)\n",
    "    >>> C4 = _lstsq(A, B)\n",
    "    >>> np.testing.assert_allclose(C1, C3)\n",
    "    >>> np.testing.assert_allclose(C1, C4)\n",
    "\n",
    "\n",
    "    >>> A[2, 3, :] = 0\n",
    "    >>> C1 = np.linalg.solve(A, B)\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    numpy.linalg.LinAlgError: Singular matrix\n",
    "    >>> C2, *_ = np.linalg.lstsq(A, B)\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    numpy.linalg.LinAlgError: 3-dimensional array given. Array must be two-dimensional\n",
    "    >>> C3 = _stable_solve(A, B)\n",
    "    >>> C4 = _lstsq(A, B)\n",
    "    >>> np.testing.assert_allclose(C3, C4)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    assert A.shape[:-2] == B.shape[:-2], (A.shape, B.shape)\n",
    "    assert A.shape[-1] == B.shape[-2], (A.shape, B.shape)\n",
    "    try:\n",
    "        return np.linalg.solve(A, B)\n",
    "    except np.linalg.LinAlgError:\n",
    "        shape_A, shape_B = A.shape, B.shape\n",
    "        assert shape_A[:-2] == shape_A[:-2]\n",
    "        working_shape_A = get_working_shape(shape_A)\n",
    "        working_shape_B = get_working_shape(shape_B)\n",
    "        A = A.reshape(working_shape_A)\n",
    "        B = B.reshape(working_shape_B)\n",
    "\n",
    "        C = np.zeros_like(B)\n",
    "        for i in range(working_shape_A[0]):\n",
    "            # lstsq is much slower, use it only when necessary\n",
    "            try:\n",
    "                C[i] = np.linalg.solve(A[i], B[i])\n",
    "            except np.linalg.LinAlgError:\n",
    "                C[i] = np.linalg.lstsq(A[i], B[i])[0]\n",
    "        return C.reshape(*shape_B)\n",
    "\n",
    "def hermite(x):\n",
    "    return x.swapaxes(-2, -1).conj()\n",
    "\n",
    "def wpe_v6(Y, taps=10, delay=3, iterations=3, psd_context=0, statistics_mode='full'):\n",
    "    \"\"\"\n",
    "    Batched WPE implementation.\n",
    "\n",
    "    Short of wpe_v7 with no extern references.\n",
    "    Applicable in for-loops.\n",
    "\n",
    "    Args:\n",
    "        Y: Complex valued STFT signal with shape (..., D, T).\n",
    "        taps: Filter order\n",
    "        delay: Delay as a guard interval, such that X does not become zero.\n",
    "        iterations:\n",
    "        psd_context: Defines the number of elements in the time window\n",
    "            to improve the power estimation. Total number of elements will\n",
    "            be (psd_context + 1 + psd_context).\n",
    "        statistics_mode: Either 'full' or 'valid'.\n",
    "            'full': Pad the observation with zeros on the left for the\n",
    "            estimation of the correlation matrix and vector.\n",
    "            'valid': Only calculate correlation matrix and vector on valid\n",
    "            slices of the observation.\n",
    "\n",
    "    Returns:\n",
    "        Estimated signal with the same shape as Y\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if statistics_mode == 'full':\n",
    "        s = Ellipsis\n",
    "    elif statistics_mode == 'valid':\n",
    "        s = (Ellipsis, slice(delay + taps - 1, None))\n",
    "    else:\n",
    "        raise ValueError(statistics_mode)\n",
    "\n",
    "    X = np.copy(Y)\n",
    "    Y_tilde = build_y_tilde(Y, taps, delay)\n",
    "    for iteration in range(iterations):\n",
    "        inverse_power = get_power_inverse(X)#和IVA里面的1/R差不多\n",
    "        Y_tilde_inverse_power = Y_tilde * inverse_power[..., None, :]\n",
    "        R = np.matmul(Y_tilde_inverse_power[s], hermite(Y_tilde[s]))\n",
    "        print('R')\n",
    "        print(np.shape(R))\n",
    "        P = np.matmul(Y_tilde_inverse_power[s], hermite(Y[s]))\n",
    "        print('P')\n",
    "        print(np.shape(P))\n",
    "        # G = _stable_solve(R, P)\n",
    "        G = np.linalg.solve(R, P)#看起来弄个简单的求逆也没啥问题，看来是作者脑子有病\n",
    "\n",
    "\n",
    "        X = Y - np.matmul(hermite(G), Y_tilde)\n",
    "\n",
    "    return X\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 3, 710)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n",
      "R\n",
      "(513, 15, 15)\n",
      "P\n",
      "(513, 15, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [37]\u001B[0m, in \u001B[0;36m<cell line: 20>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     17\u001B[0m Y \u001B[38;5;241m=\u001B[39m stft(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mstft_options)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(np\u001B[38;5;241m.\u001B[39mshape(Y))\n\u001B[1;32m---> 20\u001B[0m Z \u001B[38;5;241m=\u001B[39m \u001B[43mwpe_v6\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtaps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtaps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdelay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43miterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miterations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstatistics_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfull\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[0;32m     26\u001B[0m \u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     28\u001B[0m z \u001B[38;5;241m=\u001B[39m istft(Z, size\u001B[38;5;241m=\u001B[39mstft_options[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msize\u001B[39m\u001B[38;5;124m'\u001B[39m], shift\u001B[38;5;241m=\u001B[39mstft_options[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mshift\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     29\u001B[0m sf\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_wpe.wav\u001B[39m\u001B[38;5;124m'\u001B[39m, z\u001B[38;5;241m.\u001B[39mT , \u001B[38;5;241m16000\u001B[39m)\n",
      "Input \u001B[1;32mIn [35]\u001B[0m, in \u001B[0;36mwpe_v6\u001B[1;34m(Y, taps, delay, iterations, psd_context, statistics_mode)\u001B[0m\n\u001B[0;32m    597\u001B[0m Y_tilde \u001B[38;5;241m=\u001B[39m build_y_tilde(Y, taps, delay)\n\u001B[0;32m    598\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m iteration \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(iterations):\n\u001B[1;32m--> 599\u001B[0m     inverse_power \u001B[38;5;241m=\u001B[39m \u001B[43mget_power_inverse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;66;03m#和IVA里面的1/R差不多\u001B[39;00m\n\u001B[0;32m    600\u001B[0m     Y_tilde_inverse_power \u001B[38;5;241m=\u001B[39m Y_tilde \u001B[38;5;241m*\u001B[39m inverse_power[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m, :]\n\u001B[0;32m    601\u001B[0m     R \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmatmul(Y_tilde_inverse_power[s], hermite(Y_tilde[s]))\n",
      "Input \u001B[1;32mIn [35]\u001B[0m, in \u001B[0;36mget_power_inverse\u001B[1;34m(signal)\u001B[0m\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_power_inverse\u001B[39m(signal):\n\u001B[1;32m--> 371\u001B[0m     power \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(\u001B[43mabs_square\u001B[49m\u001B[43m(\u001B[49m\u001B[43msignal\u001B[49m\u001B[43m)\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    373\u001B[0m     eps \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-10\u001B[39m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mmax(power)\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m eps \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    375\u001B[0m         \u001B[38;5;66;03m# Special case when signal is zero.\u001B[39;00m\n\u001B[0;32m    376\u001B[0m         \u001B[38;5;66;03m# Does not happen on real data.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    379\u001B[0m         \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    380\u001B[0m         \u001B[38;5;66;03m# The scale of the power does not matter, so take 1.\u001B[39;00m\n",
      "Input \u001B[1;32mIn [35]\u001B[0m, in \u001B[0;36mabs_square\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    344\u001B[0m \n\u001B[0;32m    345\u001B[0m \u001B[38;5;124;03mParams:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;124;03m(32768,)\u001B[39;00m\n\u001B[0;32m    362\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39miscomplexobj(x):\n\u001B[1;32m--> 365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreal\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m \u001B[38;5;241m+\u001B[39m x\u001B[38;5;241m.\u001B[39mimag \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    367\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "n_sources = 3\n",
    "mixed_sig_path = 'mixed/'+str(n_sources) + 'ch/'\n",
    "save_path = 'wped/'+str(n_sources) + 'ch/'\n",
    "\n",
    "file_list = os.listdir(mixed_sig_path)\n",
    "\n",
    "stft_options = dict(size=1024, shift=1024//4)\n",
    "sampling_rate = 16000\n",
    "delay = 2\n",
    "iterations = 100\n",
    "taps = 5\n",
    "\n",
    "wav_name = file_list[4]\n",
    "\n",
    "y = sf.read(mixed_sig_path+wav_name)[0]\n",
    "y = y.T\n",
    "Y = stft(y, **stft_options).transpose(2, 0, 1)\n",
    "print(np.shape(Y))\n",
    "\n",
    "Z = wpe_v6(\n",
    "    Y,\n",
    "    taps=taps,\n",
    "    delay=delay,\n",
    "    iterations=iterations,\n",
    "    statistics_mode='full'\n",
    ").transpose(1, 2, 0)\n",
    "\n",
    "z = istft(Z, size=stft_options['size'], shift=stft_options['shift'])\n",
    "sf.write('test_wpe.wav', z.T , 16000)\n",
    "IPython.display.Audio(z[0], rate=16000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "slice(4, None, None)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice(4,None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
